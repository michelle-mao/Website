---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Michelle Mao mm87822"
date: "5/1/2020"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

### Introduction

##### For this project, I am using an updated version of the COVID-19 dataset that I used for Project 1. This is an open-access dataset by the Emergent Epidemics Lab of Northeastern University that documents individual confirmed cases of COVID-19. It was originally updated as new cases were confirmed, but the researchers appear to have stopped recording on 3/31/20 (perhaps because it was no longer realistic to attempt to document every single case in the world once COVID-19 became a pandemic). This data originally constituted two datasets, one for cases inside Hubei Province and one for cases outside of it, but because so much data has been added in the last two months, the original creators have migrated it to Github and I can no longer find the dataset for Hubei Province. Thus, the dataset I am using in this project is the dataset for cases outside of Hubei Province. As this dataset has become very large since the last time I accessed it, I cleaned up the original file slightly by removing all observations where the age was blank or entered incorrectly (e.g. 2000+ yrs old) before reading it in. The resulting dataset contains cases that were confirmed between 2/1/20 and 3/31/20, and contains several variables including including various identifiers (age, sex, location); dates of symptom onset, admission, and confirmation of the virus; symptoms; any relationships with Wuhan; other relevant medical issues; and outcome variables. Access to the dataset can be obtained through the following link:

###### https://doi.org/10.1016/S1473-3099(20)30119-5

```{R}
library(tidyverse)
setwd("C:/Users/Michelle/Desktop/Website/content")
covid <- read.csv("covid_nwu1.csv",stringsAsFactors = F)
glimpse(covid)
```

##### The "covid" dataset that I have just read in has 15,945 observations and 33 variables. It will require some clean-up as it did last time. Here, I make sure all the NAs are listed as such and remove variables that will be irrelevant to this project. I then set the variable type for the date variables to "date" and add the variable "duration", which calculates the length of time between date of symptom onset and date of outcome, as in the previous project.

```{R}
covid <- covid %>% mutate_all(function(x)ifelse(x==""|x=="N/A",NA,x)) %>% 
  select(-Ã¯..ID, -geo_resolution, -source,-sequence_available, -additional_information, -notes_for_discussion,
         -location, -admin1, -admin2, -admin3, -country_new, -admin_id,-data_moderator_initials)

covid <- covid %>% mutate(date_onset_symptoms=gsub("pre","",date_onset_symptoms),
                date_onset_symptoms=as.Date(gsub("[.]","-",date_onset_symptoms), format="%d-%m-%Y"),
                date_death_or_discharge=as.Date(gsub("[.]","-",date_death_or_discharge),format="%d-%m-%Y"),
         date_admission_hospital=as.Date(gsub("[.]","-",date_admission_hospital), format="%d-%m-%Y"),
         date_confirmation=as.Date(gsub("[.]","-",date_confirmation), format="%d-%m-%Y"),
                duration=date_death_or_discharge-date_onset_symptoms)

glimpse(covid)
```



### MANOVA

##### Here, I perform a MANOVA to test whether the numeric variables (age, latitude, longitude, duration) show a mean difference across outcome. First, I cleaned up the "age" variable so that all ages were listed as a number and large ranges of ages were removed (as they were not informative), and saved this as "tidyage". Then, I organized the "outcome" variable so that the outcome was listed as either "discharged," "died," "recovered," "stable," or "other." I saved this final dataset as "outcomes."

```{R}
covid <- covid %>% mutate(age=ifelse(age=="13 month",1.08333,age),
                          age=ifelse(age=="18 month",1.5,age),
                          age=ifelse(age=="5 month"|age=="5 months",0.41667,age),
                          age=ifelse(age=="6 months",0.5,age),
                          age=ifelse(age=="6 weeks",0.1154,age),
                          age=ifelse(age=="8 month",0.666666667,age),
                          age=ifelse(age=="9 month",0.75,age)) 

covid1 <- covid %>% filter(age!="0-60", age!="13-69", age!="15-88", age!="16-80", age!="17-66", age!="18-49", 
                           age!="18-50", age!="18-60", age!="18-65", age!="18-99", age!="18 - 100", age!="19-65",
                           age!="19-77", age!="20-57", age!="20-69", age!="20-70", age!="21-", age!="21-72",
                           age!="22-66", age!="22-80", age!="23-71", age!="23-72", age!="23-84", age!="25-59", 
                           age!="25-89", age!="27-40", age!="27-58", age!="30-60", age!="30-61", age!="30-69",
                           age!="30-70", age!="33-78", age!="34-66", age!="39-77", age!="40-69", age!="40-89",
                           age!="50-100", age!="50-99", age!="60-100", age!="60-99", age!="65-99", age!="70-100")

tidyage <- covid1 %>% mutate(age=ifelse(age=="0-10",5,age), age=ifelse(age=="0-6",3,age),age=ifelse(age=="0-9",4.5,age), 
                            age=ifelse(age=="0-18"|age=="0-19"|age=="0-20",10,age),
                            age=ifelse(age=="13-19"|age=="14-18",16,age), age=ifelse(age=="16-17",16.5,age),
                            age=ifelse(age=="18-20",19,age), age=ifelse(age=="20-39"|age=="21-39",30,age),
                            age=ifelse(age=="22-23",22.5,age), age=ifelse(age=="23-24",23.5,age),
                            age=ifelse(age=="26-27",26.5,age), age=ifelse(age=="27-29",28,age),
                            age=ifelse(age=="30-35",32.5,age), age=ifelse(age=="30-39"|age=="30-40",35,age),
                            age=ifelse(age=="34-44",39,age), age=ifelse(age=="36-45",40.5,age),
                            age=ifelse(age=="37-38",37.5,age), age=ifelse(age=="40-41",40.5,age),
                            age=ifelse(age=="40-45",42.5,age), age=ifelse(age=="41-60",50,age),
                            age=ifelse(age=="47-48",47.5,age), age=ifelse(age=="48-49",48.5,age),
                            age=ifelse(age=="20-29"|age=="20-30",25,age), age=ifelse(age=="40-49"|age=="40-50",45,age),
                            age=ifelse(age=="50-59"|age=="50-60",55,age), age=ifelse(age=="60-69",25,age),
                            age=ifelse(age=="50-69",60,age), age=ifelse(age=="54-56",55,age),
                            age=ifelse(age=="55-74"|age=="60-69"|age=="60-70",65,age),
                            age=ifelse(age=="61-80",70,age), age=ifelse(age=="74-76",75,age),
                            age=ifelse(age=="80-80",80,age), age=ifelse(age=="87-88",87.5,age),
                            age=ifelse(age=="70-79"|age=="70-82",75,age), age=ifelse(age=="80-89",85,age),
                            age=ifelse(age=="90-99",95,age), age=ifelse(age=="35-54",45,age),
                            age=as.numeric(age))

outcomes <- tidyage %>% mutate(outcome=ifelse(outcome=="discharge"|outcome=="Discharged"|
                                              outcome=="released from quarantine","discharged",outcome),
                        outcome=ifelse(outcome=="death"|outcome=="dead"|outcome=="Dead"|outcome=="Death"|
                                         outcome=="Deceased"|outcome=="Died","died",outcome),
                        outcome=ifelse(outcome=="Recovered","recovered",outcome),
                        outcome=ifelse(outcome=="Stable"|outcome=="stable condition","stable",outcome),
                        outcome=ifelse(outcome!="discharged" & outcome!="died" & outcome!="recovered" &
                                         outcome!="stable","other",outcome)) %>%
  mutate(duration=as.numeric(duration)) 
```

##### Performing the MANOVA, univariate ANOVAs, and post-hoc t-tests:

```{R}
outcomes1 <- outcomes %>% filter(duration!="NA")
man <- manova(cbind(age,latitude,longitude,duration)~outcome, data=outcomes1)
summary(man)
summary.aov(man)

pairwise.t.test(outcomes1$age,outcomes1$outcome,p.adj="none")
pairwise.t.test(outcomes1$latitude,outcomes1$outcome,p.adj="none")
pairwise.t.test(outcomes1$longitude,outcomes1$outcome,p.adj="none")
pairwise.t.test(outcomes1$duration,outcomes1$outcome,p.adj="none")
```

##### There was no duration data for observations with outcomes of either "stable" or "other," so analysis was only done on the "died," "discharged," and "recovered" outcomes. Overall, at least one of the numeric variables shows a mean difference by outcome with a p-value of < 2.2e-16. Univariate ANOVAs show that there is a significant mean difference in outcome for all four variables when using an unadjusted significance level. A total of 17 tests (1 MANOVA, 4 ANOVAs, 12 t-tests) were performed, meaning the probability of at least one type I error is 1 - 0.95^17 = 0.5818797 if unadjusted. The Bonferroni adjustment puts the new significance level at 0.05/17 = 0.002941176.

##### After adjusting the significance level, all numeric variables except longitude show a significant mean difference across outcomes based on the univariate ANOVAs. The post-hoc t-tests show that there is a significant mean difference in both age and latitude across between patients who died and patients who were discharged, as well as between patients who died and patients who recovered. The mean difference in longitude is not significant for any combination of outcomes. There is a significant mean difference in duration between patients who died and patients who were discharged.

##### MANOVA is performed under several assumptions: multivariate normal distribution, same variance/covariance for all groups, sensitivity to multicollinearity, more samples than variables, and sensitivity to zeroes and outliers. My data meets the assumption of having more samples than variables and is probably not collinear, but it is possible that it violates the assumptions of a multivariate normal distribution, equal variance/covariance, and zeroes/outliers.



### Randomization Test

##### Here, I perform a randomization test to see if there is a significant mean difference in age across the chronic disease binary (TRUE if the patient has a chronic disease and FALSE if they do not). The null hypothesis is that there is no difference between the means of the ages of patients who have a chronic disease and patients who do not have a chronic disease. The alternative hypothesis is that there is a difference between the means of the ages of patients who have a chronic disease and patients who do not have a chronic disease.

```{R}
tidyage %>% group_by(chronic_disease_binary) %>% summarize(meansage=mean(age)) %>% summarize(mean_diff=diff(meansage))

rand_age <- vector()
for(i in 1:5000){
new <- data.frame(age=sample(tidyage$age), cdb=tidyage$chronic_disease_binary) 
rand_age[i]<-mean(new[new$cdb=="FALSE",]$age)-mean(new[new$cdb=="TRUE",]$age)}

mean(rand_age > 5.465774)*2

hist(rand_age,main="",ylab=""); abline(v = 5.465774,col="red")
```

##### The p-value is 0, therefore the null hypothesis is rejected; there is 0% chance of a mean difference being as extreme as 5.465774 under the assumption of no association between age and chronic disease. In other words, there is a significant difference between the ages of people who do and do not have a chronic disease. For this reason, the line marking the actual mean difference does not show up on the histogram showing distributions of randomized mean differences.



### Linear Regression

##### Here, I perform a linear regression predicting duration from age and chronic disease binary. First, I mean-centered age as it is a numeric variable. Then, I performed the linear regression.

```{R}
tidyage_c <- tidyage %>% mutate(age_c=age-mean(age,na.rm=T)) %>% filter(duration!="NA") %>%
  mutate(duration=as.numeric(duration))
fit1 <- lm(duration ~ age_c * chronic_disease_binary, data=tidyage_c)
summary(fit1)
```

##### The intercept shows that, controlling for all other variables, patients without a chronic disease and with an age equal to the mean age are spend an average of 19.47356 days between being confirmed and having an outcome recorded. Controlling for all other variables, for every one year increase in age, the duration increases by 0.04809 days. Controlling for all other variables, patients who have a chronic disease have a duration that is on average 1.98093 days less than those who do not have a chronic disease. Controlling for all other variables, the slope for age on duration is 0.14375 lower for patients with a chronic disease compared to patients who do not have a chronic disease.

##### Below, I test the assumptions of linearity, normality, and homoskedasticity for this model.

```{R}
library(lmtest)
library(sandwich)

resids <- fit1$residuals
fitvals <- fit1$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, col="red")

bptest(fit1)

ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids), color='red')
```

##### The data appears to be linear and homoskedastic when eyeballing, and this is confirmed by the Breusch-Pagan test (p=0.1113, retain null hypothesis of homoskedasticity). The qq-plot shows the data to meet the assumption of normality.

##### Recomputing regression results with robust standard errors:

```{R}
coeftest(fit1, vcov = vcovHC(fit1))
```

##### After using robust standard errors, the standard errors have increased for every coefficient, and the p-values have also increased, although the significant p-values remain significant and the non-significant p-values remain non-significant. My model explains only 0.07219, or 7%, of the data (0.06004 or 6% when adjusted).



### Bootstrapped Standard Errors

##### Here, I compute bootstrapped standard errors on my linear regression model above by resampling the residuals.

```{R}
resid_boot <- replicate(5000,{
new_resids <- sample(resids,replace=TRUE)
tidyage_c$new_y <- fitvals + new_resids 
fit1 <- lm(new_y~age_c*chronic_disease_binary,data=tidyage_c) 
coef(fit1) 
})

resid_boot %>% t %>% as.data.frame %>% summarize_all(sd)
```

##### After bootstrapping, the standard errors for all coefficients decreased compared to the standard errors in the original model. This means that they are even further from the robust standard errors than the original standard errors are. The decreases in standard error that result from bootstrapping are of a very small magnitude, so the p-values would not be expected to change much either and would follow the trend of the standard errors. The p-values that are significant would remain significant, and the p-values that are non-significant would remain non-significant.



### Logistic Regression

##### Here, I predict outcome from age and chronic disease using a logistic regression. I expect that these variables will have some significant impact on the outcome of the patient, as older patients tend to have weaker immune systems and chronic diseases tend to exacerbate other illnesses. First, I changed the "outcome" variable into a binary where 1 represents death and 0 represents survival, and then I performed the regression and exponentiated the coefficients:

```{R}
outcomes2 <- outcomes %>% mutate(outcome=ifelse(outcome=="died",1,0)) %>%
  filter(outcome!="NA",age!="NA",chronic_disease_binary!="NA")

logfit1 <- glm(outcome ~ age+chronic_disease_binary,data=outcomes2,family="binomial")
summary(logfit1)
exp(coef(logfit1))%>%round(4)%>%t
```

##### Controlling for other factors, the predicted odds of death is 0.0013 for a patient who is 0 years old and does not have a chronic disease. The odds of death are multiplied by 1.0955 for every one-year increase in age. The odds of death for patients who have a chronic disease are 11.7131 times the odds of death for patients who do not.

##### Here, I create a confusion matrix for the logistic regression.

```{R}
probs1 <- predict(logfit1,type="response") 
table(predict=as.numeric(probs1>.5),truth=outcomes2$outcome) %>% addmargins
```

##### The accuracy is (460 + 149)/691 = 0.8813314; the sensitivity is 149/197 = 0.7563452; the specificity is 460/494 = 0.9311741; and the recall is 149/183 = 0.8142077. Overall, the 88% accuracy means the model does a decent, but not stellar, job of predicting whether the patient died. It does a better job of predicting patients who did not die (93%) than patients who did die (76%). The recall (81%) shows that there are a few patients that the model classified as having died when they actually survived.

##### Below is a density plot of the log-odds by outcome.

```{R}
outcomes2$logit <- predict(logfit1,type="link") 

outcomes2 %>% ggplot() + geom_density(aes(logit,fill=as.factor(outcome)), alpha=.4) +
  theme(legend.position=c(.9,.9)) + geom_vline(xintercept=0) + xlab("logit (log-odds)") +
  geom_rug(aes(logit,color=as.factor(outcome))) +
  geom_text(x=-3,y=0.1,label="TN = 460") +
  geom_text(x=-1.75,y=.008,label="FN = 48") +
  geom_text(x=1,y=.006,label="FP = 34") +
  geom_text(x=2,y=0.1,label="TP = 149")
```

##### Below is a plot of the ROC curve for the regression.

```{R}
library(plotROC) 
outcomes2$probs1 <- predict(logfit1,type="response")
ROC1 <- ggplot(outcomes2) + geom_roc(aes(d=outcome,m=probs1), n.cuts=0)
ROC1
calc_auc(ROC1)
```

##### The ROC curve is nearly a right angle and the AUC is 0.9275879, which means that the model does a great job overall of predicting whether the patient died or survived based on their age and whether they have a chronic disease.

##### Below, I perform a 10-fold cross-validation to see how my model will perform on data outside of what it has been trained on.

```{R}
# Classification diagnostics function
class_diag<-function(probs,truth){
  
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  prediction<-ifelse(probs>.5,1,0)
  acc=mean(truth==prediction)
  sens=mean(prediction[truth==1]==1)
  spec=mean(prediction[truth==0]==0)
  ppv=mean(truth[prediction==1]==1)
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}


# 10-fold CV

k=10

data1 <- outcomes2[sample(nrow(outcomes2)),] 
folds <- cut(seq(1:nrow(outcomes2)),breaks=k,labels=F) 

diags <- NULL
for(i in 1:k){ 
  train<-data1[folds!=i,] 
  test<-data1[folds==i,] 
  
  truth<-test$outcome
  
  fit<- glm(outcome ~ age+chronic_disease_binary, data=train, family="binomial")
  probs<- predict(fit,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(probs,truth)) 
}

summarize_all(diags,mean)
```

##### The AUC from the cross-validation is 0.9247086, meaning that my model did very nearly as well predicting new data as it did on the data on which it was trained. There is nearly no overfitting. The sensitivity is 0.7628949, while the specificity is 0.9308911; these are very close to the numbers from the original logistic regression.



### LASSO

##### To see which variables are most important in predicting patient outcome, I performed a LASSO regression. I removed the following variables from my LASSO: the date variables, as it would not make sense to include them due to their format; "symptoms", "travel_history_location", and "chronic_disease", as they are not standardized; "travel_history_binary", as it is uncertain what it is recording; "reported_market_exposure", as it does not contain enough data; and "city", "province", and "lives_in_Wuhan" because if I had included them, there would not have been enough data to create a reasonable model and I felt that "country" as a location-related predictor would be sufficient for the purposes of this project.

```{R}
library(glmnet)

outcomes3 <- outcomes2 %>%
  select(-logit,-probs1,-date_onset_symptoms,-date_admission_hospital,-date_confirmation,
         -date_death_or_discharge,-symptoms,travel_history_dates,-travel_history_binary,
         -reported_market_exposure,-chronic_disease,-travel_history_dates,
         -travel_history_location,-city,-province,-lives_in_Wuhan) %>% na.omit()

logfit2 <- glm(outcome ~ .,data=outcomes3,family="binomial")

x <- model.matrix(logfit2)
x <- scale(x)
y <- as.matrix(outcomes3$outcome)

cv1 <- cv.glmnet(x[,-1],y,family='binomial')
lasso1 <- glmnet(x[,-1],y,family='binomial',lambda=cv1$lambda.1se)
coef(lasso1)
```

##### The LASSO results show that the most significant predictors of the patient's outcome are their age, whether they have a chronic disease, the latitude of their location, whether they are from China, and whether they are from Gambia. Latitude is probably related to the country predictors, and the presence of China as a predictor may be due to its overrepresentation in the dataset. Using the variables LASSO selected, I then performed a 10-fold CV on a new logistic regression:

```{R}
outcomes3 <- outcomes3 %>% mutate(China=ifelse(country=="China",1,0),Gambia=ifelse(country=="Gambia",1,0))

k=10

data1 <- outcomes3[sample(nrow(outcomes3)),] 
folds <- cut(seq(1:nrow(outcomes3)),breaks=k,labels=F) 

diags <- NULL
for(i in 1:k){ 
  train<-data1[folds!=i,] 
  test<-data1[folds==i,] 
  
  truth<-test$outcome
  
  fit<- glm(outcome ~ age+chronic_disease_binary+latitude+China+Gambia, data=train, family="binomial")
  probs<- predict(fit,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(probs,truth)) 
}

summarize_all(diags,mean)
```

##### The AUC for the new model using the variables from LASSO is 0.9678614, which is higher than the AUC from my previous model that used only age and the chronic disease binary as predictors. While this model is more flexible, it also does a better job of predicting based on out-of-sample data. 

##### It is worth noting that all models and analyses in this project are limited by the original COVID-19 dataset, in which cases from China, where the focus was at the beginning of the pandemic, are overrepresented, and there are many incomplete entries. However, it is not surprising that my results show age and chronic disease to be significant predictors of outcome; it would be interesting to see how this model would perform on more current data.
